# Ã–lÃ§eklenebilirlik Analizi

## ğŸ“‹ Ä°Ã§indekiler
1. [Ã–lÃ§eklenebilirlik Nedir?](#Ã¶lÃ§eklenebilirlik-nedir)
2. [NasÄ±l Eklendi?](#nasÄ±l-eklendi)
3. [NasÄ±l Ã‡alÄ±ÅŸÄ±r?](#nasÄ±l-Ã§alÄ±ÅŸÄ±r)
4. [SonuÃ§lar Neye GÃ¶re DeÄŸiÅŸir?](#sonuÃ§lar-neye-gÃ¶re-deÄŸiÅŸir)
5. [KullanÄ±m](#kullanÄ±m)
6. [1000+ DÃ¼ÄŸÃ¼m DesteÄŸi](#1000-dÃ¼ÄŸÃ¼m-desteÄŸi)

---

## ğŸ“ˆ Ã–lÃ§eklenebilirlik Nedir?

Ã–lÃ§eklenebilirlik, bir algoritmanÄ±n **aÄŸ boyutu arttÄ±kÃ§a** performansÄ±nÄ±n nasÄ±l deÄŸiÅŸtiÄŸini Ã¶lÃ§er.

### Temel Sorular
- 250 dÃ¼ÄŸÃ¼mlÃ¼ aÄŸda Ã§alÄ±ÅŸan algoritma 1000 dÃ¼ÄŸÃ¼mde nasÄ±l performans gÃ¶sterir?
- Hangi algoritma bÃ¼yÃ¼k aÄŸlarda daha verimli?
- Zaman karmaÅŸÄ±klÄ±ÄŸÄ± pratik limitleri nelerdir?

### Ã–nemli Metrikler
| Metrik | AÃ§Ä±klama |
|--------|----------|
| **Ã‡alÄ±ÅŸma SÃ¼resi (ms)** | Optimizasyon ne kadar sÃ¼rdÃ¼? |
| **BaÅŸarÄ± OranÄ±** | Ã‡Ã¶zÃ¼m bulunabiliyor mu? |
| **Ortalama Maliyet** | Ã‡Ã¶zÃ¼m kalitesi korunuyor mu? |
| **HafÄ±za KullanÄ±mÄ± (MB)** | RAM tÃ¼ketimi artÄ±yor mu? |

---

## ğŸ”§ NasÄ±l Eklendi?

### OluÅŸturulan Dosyalar

| Dosya | AmaÃ§ |
|-------|------|
| `app/src/experiments/scalability_analyzer.py` | GeliÅŸmiÅŸ Ã¶lÃ§eklenebilirlik analiz motoru |

### Mevcut BileÅŸenler (GeniÅŸletildi)

| Dosya | DeÄŸiÅŸiklik |
|-------|------------|
| `app/src/ui/main_window.py` | `ScalabilityWorker` - 1000+ dÃ¼ÄŸÃ¼m desteÄŸi |
| `app/src/ui/components/scalability_dialog.py` | SonuÃ§ gÃ¶rselleÅŸtirme |

---

## âš™ï¸ NasÄ±l Ã‡alÄ±ÅŸÄ±r?

### Analiz AlgoritmasÄ±

```
1. DÃ¼ÄŸÃ¼m BoyutlarÄ± Belirlenir
   â””â”€â”€ Ã–rnek: [100, 250, 500, 750, 1000, 1500, 2000]

2. Her Boyut Ä°Ã§in:
   â”œâ”€â”€ Rastgele graf oluÅŸtur (ErdÅ‘s-RÃ©nyi)
   â”œâ”€â”€ Seyreklik ayarla (bÃ¼yÃ¼k aÄŸlarda daha seyrek)
   â”œâ”€â”€ Test case'ler Ã¼ret
   â””â”€â”€ Her algoritma iÃ§in:
       â”œâ”€â”€ n_repeats tekrar Ã§alÄ±ÅŸtÄ±r
       â”œâ”€â”€ SÃ¼re Ã¶lÃ§ (tracemalloc ile hafÄ±za da)
       â””â”€â”€ Ä°statistik topla

3. SonuÃ§larÄ± Analiz Et
   â”œâ”€â”€ En hÄ±zlÄ± algoritma
   â”œâ”€â”€ En Ã¶lÃ§eklenebilir (zaman artÄ±ÅŸ oranÄ± en dÃ¼ÅŸÃ¼k)
   â””â”€â”€ BÃ¼yÃ¼k aÄŸ Ã¶nerileri
```

### Seyreklik AyarlamasÄ± (Kritik)

BÃ¼yÃ¼k aÄŸlarda yoÄŸunluk dÃ¼ÅŸÃ¼rÃ¼lÃ¼r, aksi halde hafÄ±za taÅŸar:

```python
if n_nodes <= 250:
    p = 0.15      # ~9000 edge
elif n_nodes <= 500:
    p = 0.08      # ~20000 edge
elif n_nodes <= 1000:
    p = 0.04      # ~40000 edge
else:
    p = 0.02      # >1000 dÃ¼ÄŸÃ¼m iÃ§in Ã§ok seyrek
```

### HafÄ±za Ä°zleme

```python
import tracemalloc

tracemalloc.start()
# ... algorithm runs ...
current, peak = tracemalloc.get_traced_memory()
memory_mb = peak / (1024 * 1024)
tracemalloc.stop()
```

---

## ğŸ“Š SonuÃ§lar Neye GÃ¶re DeÄŸiÅŸir?

### 1. DÃ¼ÄŸÃ¼m SayÄ±sÄ±
| DÃ¼ÄŸÃ¼m | Beklenen SÃ¼re | Edge SayÄ±sÄ± (p=deÄŸiÅŸken) |
|-------|---------------|--------------------------|
| 100 | 10-50 ms | ~750 |
| 250 | 50-200 ms | ~4500 |
| 500 | 100-500 ms | ~10000 |
| 1000 | 200-1500 ms | ~20000 |
| 2000 | 500-5000 ms | ~40000 |

### 2. Algoritma TÃ¼rÃ¼

| Algoritma | Ã–lÃ§eklenebilirlik | AÃ§Ä±klama |
|-----------|-------------------|----------|
| **GA** | â­â­â­ | PopÃ¼lasyon boyutu sabit kalabilir |
| **ACO** | â­â­ | Feromon matrisi O(nÂ²) yer kaplar |
| **PSO** | â­â­â­ | ParÃ§acÄ±k sayÄ±sÄ± sabit |
| **SA** | â­â­â­â­ | Tek Ã§Ã¶zÃ¼mle Ã§alÄ±ÅŸÄ±r, Ã§ok verimli |
| **Q-Learning** | â­â­ | Q-table boyutu O(n Ã— k) |
| **SARSA** | â­â­ | Q-Learning ile benzer |

### 3. Graf YoÄŸunluÄŸu (p)
- YoÄŸun graf: Daha fazla komÅŸu, daha uzun keÅŸif
- Seyrek graf: Az yol, hÄ±zlÄ± ama kalitesiz Ã§Ã¶zÃ¼m riski

### 4. Test SayÄ±sÄ± ve Tekrar
- Daha fazla test = daha gÃ¼venilir istatistik
- VarsayÄ±lan: 5 test case Ã— 3 tekrar = 15 Ã§alÄ±ÅŸtÄ±rma/algoritma

---

## ğŸ–¥ï¸ KullanÄ±m

### UI'dan (Mevcut - KÃ¼Ã§Ã¼k Ã–lÃ§ek)
1. Graf yÃ¼kleyin (herhangi bir boyut)
2. SaÄŸ panelde **"Ã–lÃ§eklenebilirlik"** kartÄ±nÄ± bulun
3. **"Analiz Et"** butonuna tÄ±klayÄ±n
4. SonuÃ§ dialog'unu inceleyin

### Extended Analyzer (BÃ¼yÃ¼k Ã–lÃ§ek - Kod)
```python
from src.experiments.scalability_analyzer import ScalabilityAnalyzer

analyzer = ScalabilityAnalyzer(
    node_sizes=[100, 250, 500, 750, 1000, 1500, 2000],
    n_repeats=3,
    n_test_cases=5,
    algorithms=['ga', 'aco', 'pso', 'sa']
)

def progress_callback(current, total, message):
    print(f"[{current}/{total}] {message}")

report = analyzer.run_analysis()

print(f"En HÄ±zlÄ±: {report.fastest_algorithm}")
print(f"En Ã–lÃ§eklenebilir: {report.most_scalable}")

for rec in report.recommendations:
    print(rec)
```

---

## ğŸš€ 1000+ DÃ¼ÄŸÃ¼m DesteÄŸi

### Zorluklar

| Zorluk | Ã‡Ã¶zÃ¼m |
|--------|-------|
| HafÄ±za taÅŸmasÄ± | Seyreklik (p) otomatik azaltÄ±lÄ±r |
| UI donmasÄ± | QThread ile arka planda Ã§alÄ±ÅŸma |
| Uzun sÃ¼re | Progress callback ile takip |
| Edge patlamasÄ± | Lazy evaluation, akÄ±llÄ± keÅŸif |

### BÃ¼yÃ¼k AÄŸlarda Performans Ä°puÃ§larÄ±

1. **Seyreklik ayarÄ± kritik** - 2000 dÃ¼ÄŸÃ¼mde p=0.02 kullanÄ±n
2. **Paralel iÅŸlem** - GA'da `use_parallel='auto'`
3. **Early stopping** - YakÄ±nsama saÄŸlandÄ±ÄŸÄ±nda dur
4. **Batch processing** - BÃ¼yÃ¼k popÃ¼lasyonlarÄ± parÃ§ala

### Ã–rnek 1000 DÃ¼ÄŸÃ¼m SonuÃ§larÄ±

```
DÃ¼ÄŸÃ¼m: 1000, Edge: ~20000

Algoritma        | Ortalama SÃ¼re | BaÅŸarÄ± OranÄ± | HafÄ±za
-----------------|---------------|--------------|--------
SA              | 320 ms        | 100%         | 45 MB
PSO             | 580 ms        | 95%          | 62 MB
GA              | 850 ms        | 98%          | 78 MB
ACO             | 1200 ms       | 92%          | 120 MB
Q-Learning      | 2500 ms       | 85%          | 95 MB
```

---

## ğŸ“ Kod YapÄ±sÄ±

### ScalabilityDataPoint
```python
@dataclass
class ScalabilityDataPoint:
    node_count: int
    edge_count: int
    algorithm: str
    avg_time_ms: float
    std_time_ms: float
    min_time_ms: float
    max_time_ms: float
    success_rate: float
    avg_cost: float
    memory_mb: float
```

### ScalabilityReport
```python
@dataclass
class ScalabilityReport:
    data_points: List[ScalabilityDataPoint]
    node_sizes: List[int]
    algorithms: List[str]
    total_time_sec: float
    fastest_algorithm: str
    most_scalable: str
    recommendations: List[str]
    
    def get_time_by_algorithm(self, algorithm) -> List[float]
    def get_time_by_nodes(self, node_count) -> Dict[str, float]
```

### ScalabilityAnalyzer
```python
class ScalabilityAnalyzer:
    def __init__(
        self,
        node_sizes=[100, 250, 500, 750, 1000, 1500, 2000],
        n_repeats=3,
        n_test_cases=5,
        algorithms=None,
        progress_callback=None
    )
    
    def run_analysis(self) -> ScalabilityReport
    def _create_test_graph(self, n_nodes) -> tuple
    def _test_algorithm(self, graph, algo_key, ...) -> ScalabilityDataPoint
    def _analyze_results(self, report) -> None
```

---

## ğŸ“ˆ Ã–rnek Grafik Ã‡Ä±ktÄ±sÄ±

```
Ã‡alÄ±ÅŸma SÃ¼resi vs DÃ¼ÄŸÃ¼m SayÄ±sÄ±
                                                        
    2500 â”¤                                         â•­â”€â”€
         â”‚                                    â•­â”€â”€â”€â”€â•¯  
    2000 â”¤                               â•­â”€â”€â”€â”€â•¯       
         â”‚                          â•­â”€â”€â”€â”€â•¯            
    1500 â”¤               ACO   â•­â”€â”€â”€â”€â•¯                 
         â”‚                â•­â”€â”€â”€â”€â•¯                      
    1000 â”¤           â•­â”€â”€â”€â”€â•¯                           
         â”‚      â•­â”€â”€â”€â”€â•¯       GA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       
     500 â”¤ â•­â”€â”€â”€â”€â•¯                                     
         â”‚â•­â•¯   PSO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       
       0 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       
         100   250   500   750   1000  1500  2000
                       DÃ¼ÄŸÃ¼m SayÄ±sÄ±
```

---

**Son GÃ¼ncelleme:** 28 AralÄ±k 2025  

